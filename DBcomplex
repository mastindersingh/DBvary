

"""
main.py

Example KPI automation script with placeholders for {prev_month_start}, {start_date}, and {end_date}
in a PostgreSQL query, plus integration with SQL Server and JIRA.
"""

import os
import logging
import argparse
from datetime import datetime, timedelta, timezone

import psycopg2
import pymssql
from jira import JIRA, JIRAError
from requests.exceptions import RequestException

# This import assumes you have a config.py file with a CONFIG dictionary
from config import CONFIG

# -------------------------------------------------------------------------
# Logging Setup
# -------------------------------------------------------------------------
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# -------------------------------------------------------------------------
# PostgreSQL Database Class
# -------------------------------------------------------------------------
class PostgreSQL:
    """
    Manages PostgreSQL database connections and operations.
    """

    def __init__(self, params):
        """Initialize PostgreSQL connection."""
        try:
            self.pg_conn = psycopg2.connect(
                host=params["pisi_db_server"],
                port=int(params["pisi_db_port"]),
                dbname=params["pisi_db_name"],
                user=params["pisi_db_user"],
                password=params["pisi_db_pass"]
            )
            logger.info("Connected to PostgreSQL successfully.")
        except psycopg2.Error as err:
            raise RuntimeError(f"Error connecting to PostgreSQL: {err}") from err

    def fetch_kpi_measure_list(self):
        """Fetch KPI queries from PostgreSQL (kpi_schema.kpi_measures)."""
        try:
            with self.pg_conn.cursor() as cursor:
                cursor.execute("""
                    SELECT kn.service_id, km.configuration_id, km.datasource_id,
                           km.metric_name, km.query_text, kd.datasource_name
                    FROM kpi_schema.kpi_service_names kn
                    JOIN kpi_schema.kpi_measures km ON kn.service_id = km.service_id
                    JOIN kpi_schema.kpi_datasources kd ON km.datasource_id = kd.datasource_id
                    ORDER BY km.datasource_id ASC
                """)
                rows = cursor.fetchall()
                return [
                    {
                        "service_id": row[0],
                        "configuration_id": row[1],
                        "datasource_id": row[2],
                        "metric_name": row[3],
                        "query_text": row[4],
                        "datasource_name": row[5]
                    }
                    for row in rows
                ]
        except psycopg2.Error as err:
            raise RuntimeError(f"Error fetching KPI measure list: {err}") from err

    def execute_query(self, query):
        """Execute a PostgreSQL query and return all rows."""
        try:
            with self.pg_conn.cursor() as cursor:
                cursor.execute(query)
                return cursor.fetchall()
        except psycopg2.Error as err:
            raise RuntimeError(f"Error executing PostgreSQL query: {err}") from err

    def insert_kpi_tracking(self, data):
        """
        Insert KPI results into kpi_schema.kpi_tracking with an upsert (ON CONFLICT).
        Each record is a tuple:
            (service_id, configuration_id, application_id, metric_name, metric_value, startdt, end_dt)
        """
        try:
            with self.pg_conn.cursor() as cursor:
                insert_query = """
                    INSERT INTO kpi_schema.kpi_tracking (
                        service_id, configuration_id, application_id, metric_name, metric_value, startdt, end_dt
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (service_id, configuration_id, application_id, metric_name, startdt, end_dt)
                    DO NOTHING;
                """
                for record in data:
                    logger.info(f"Inserting record: {record}")
                    cursor.execute(insert_query, record)
                self.pg_conn.commit()
                logger.info("Data inserted into kpi_tracking table successfully.")
        except psycopg2.Error as err:
            raise RuntimeError(f"Error inserting data into kpi_tracking table: {err}") from err

    def close(self):
        """Close PostgreSQL connection."""
        if self.pg_conn:
            self.pg_conn.close()
            logger.info("PostgreSQL connection closed.")

# -------------------------------------------------------------------------
# MSSQL Database Class
# -------------------------------------------------------------------------
class MSSQLDatabase:
    """
    Manages MSSQL database connections and operations.
    """

    def __init__(self, params):
        """Initialize MSSQL connection."""
        try:
            self.ms_conn = pymssql.connect(
                server=f"{params['eft_datamart_host']}:{params['eft_datamart_port']}\\{params['eft_datamart_instance']}",
                user=f"AD-ENT\\{params['pisi_service_user']}",
                password=params["pisi_service_pass"],
                database=params["eft_datamart_db_name"]
            )
            logger.info("Connected to MSSQL successfully.")
        except pymssql.Error as err:
            raise RuntimeError(f"Error connecting to MSSQL: {err}") from err

    def execute_query(self, query):
        """Execute an MSSQL query and return all rows as dicts."""
        try:
            with self.ms_conn.cursor(as_dict=True) as cursor:
                cursor.execute(query)
                return cursor.fetchall()
        except pymssql.Error as err:
            raise RuntimeError(f"Error executing MSSQL query: {err}") from err

    def close(self):
        """Close MSSQL connection."""
        if self.ms_conn:
            self.ms_conn.close()
            logger.info("MSSQL connection closed.")

# -------------------------------------------------------------------------
# Jira API Class
# -------------------------------------------------------------------------
class JiraAPI:
    """
    Manages JIRA API connections and operations.
    """

    MAX_RESULTS = 50

    def __init__(self, server, token):
        """Initialize Jira API connection."""
        if server:
            self.jira_conn = JIRA(server=server, token_auth=token)
            logger.info(f"Connected to JIRA server: {server}")

    def get_issues(self, jql, max_retries=3):
        """Fetch issues from Jira with pagination and retries."""
        start_at = 0
        all_issues = []
        retries = 0

        while True:
            try:
                result = self.fetch_issues_with_jql(jql, start_at)
                if not result:
                    break
                all_issues.extend(result)
                if len(result) < self.MAX_RESULTS:
                    break
                start_at += self.MAX_RESULTS
            except RequestException:
                if retries < max_retries:
                    retries += 1
                    logger.info(f"Retrying... ({retries}/{max_retries})")
                    continue
                break
            except JIRAError as e:
                logger.error(f"JIRA error fetching issues: {e}")
                break
            except Exception as e:
                logger.error(f"Error fetching issues: {e}")
                break
        return self.extract_issue_data(all_issues)

    def fetch_issues_with_jql(self, jql, start_at):
        """Use JIRA library to fetch issues for a given JQL and start index."""
        logger.info("Fetching issues with JQL: %s, start_at: %s", jql, start_at)
        result = self.jira_conn.search_issues(
            jql_str=jql,
            maxResults=self.MAX_RESULTS,
            startAt=start_at
        )
        if not result:
            logger.info("No issues returned for JQL: %s, start_at: %s", jql, start_at)
        return result

    def extract_issue_data(self, all_issues):
        """
        Extract relevant fields from a list of JIRA issues.
        Example: customfield_11400 as app ID, resolutiondate, etc.
        """
        data = []
        for issue in all_issues:
            if issue.fields.customfield_11400 is not None:
                app_id = issue.fields.customfield_11400[0]
                logger.info("Issue %s customfield_11400 value: %s", issue.key, issue.fields.customfield_11400)
                data.append((issue.key, issue.fields.resolutiondate, app_id))
            else:
                logger.warning("Issue %s does not have customfield_11400", issue.key)
        return data

# -------------------------------------------------------------------------
# KPI Processing Functions
# -------------------------------------------------------------------------
def process_kpi(kpi, db, mssql, jira_proxy, start_date, end_date):
    """
    Process KPI data for a given date range (day by day).
    """
    try:
        kpi_tracking_data = []
        current_date = start_date
        while current_date <= end_date:
            next_date = current_date + timedelta(days=1)
            logger.info("Processing KPI: %s for date range %s to %s",
                        kpi["metric_name"],
                        current_date.strftime("%Y-%m-%d"),
                        next_date.strftime("%Y-%m-%d"))

            # Dispatch to the right function based on datasource name
            if kpi["datasource_name"] == "JIRA":
                process_jira_kpi(kpi, jira_proxy, current_date, next_date, kpi_tracking_data)
            elif kpi["datasource_name"] == "SQL Server":
                process_sql_server_kpi(kpi, mssql, current_date, next_date, kpi_tracking_data)
            elif kpi["datasource_name"] == "PostgreSQL":
                # Compute the previous month's start date
                first_day_current_month = current_date.replace(day=1)
                prev_month_start = first_day_current_month - timedelta(days=1)
                prev_month_start = prev_month_start.replace(
                    day=1, hour=0, minute=0, second=0, microsecond=0, tzinfo=timezone.utc
                )
                process_postgresql_kpi(
                    kpi,
                    db,
                    prev_month_start,
                    current_date,
                    next_date,
                    kpi_tracking_data
                )

            current_date = next_date

        # Insert the collected KPI data into the tracking table
        insert_kpi_tracking_data(db, kpi_tracking_data)
    except (psycopg2.Error, pymssql.Error, JIRAError, RequestException) as e:
        logger.error("Error processing KPI %s: %s", kpi["metric_name"], e)

def process_jira_kpi(kpi, jira_proxy, current_date, next_date, kpi_tracking_data):
    """
    Process KPI data from JIRA for a given date range.
    Replaces {start_date} and {end_date} in the JQL query.
    """
    jql_query = (kpi["query_text"]
                 .replace("{start_date}", current_date.strftime("%Y/%m/%d %H:%M"))
                 .replace("{end_date}", next_date.strftime("%Y/%m/%d %H:%M")))
    logger.info("Processing JQL query: %s", jql_query)
    issues = jira_proxy.get_issues(jql_query)

    for issue in issues:
        # issue is a tuple: (issue_key, resolutiondate, app_id)
        app_id = issue[2]
        kpi_tracking_data.append((
            kpi["service_id"],
            kpi["configuration_id"],
            app_id,
            kpi["metric_name"],
            issue[0],  # issue_key as metric_value
            current_date,
            next_date
        ))

def process_sql_server_kpi(kpi, mssql, current_date, next_date, kpi_tracking_data):
    """
    Process KPI data from SQL Server for a given date range.
    Replaces {prev_month_start}, {start_date}, and {end_date}.
    """
    # Calculate prev_month_start
    first_day_current_month = current_date.replace(day=1)
    prev_month_start = first_day_current_month - timedelta(days=1)
    prev_month_start = prev_month_start.replace(
        day=1, hour=0, minute=0, second=0, microsecond=0, tzinfo=timezone.utc
    )

    logger.info("Original SQL Server query: %s", kpi["query_text"])
    query = (kpi["query_text"]
             .replace("{start_date}", current_date.strftime("%Y/%m/%d %H:%M"))
             .replace("{end_date}", next_date.strftime("%Y/%m/%d %H:%M"))
             .replace("{prev_month_start}", prev_month_start.strftime("%Y/%m/%d %H:%M")))

    logger.info("Modified SQL Server query: %s", query)
    results = mssql.execute_query(query)

    for row in results:
        # Example fields: row["DISTRIBUTED_APP_ID"], row["PROBLEM_NUMBER"]
        kpi_tracking_data.append((
            kpi["service_id"],
            kpi["configuration_id"],
            row["DISTRIBUTED_APP_ID"],
            kpi["metric_name"],
            row["PROBLEM_NUMBER"],
            current_date,
            next_date
        ))

def process_postgresql_kpi(kpi, db, prev_month_start, current_date, next_date, kpi_tracking_data):
    """
    Process KPI data from PostgreSQL for a given date range.
    Replaces {prev_month_start}, {start_date}, and {end_date}.
    """
    logger.info("Original PostgreSQL query: %s", kpi["query_text"])

    # Convert datetimes to a format Postgres can parse reliably
    prev_str = prev_month_start.strftime("%Y-%m-%d %H:%M:%S")
    start_str = current_date.strftime("%Y-%m-%d %H:%M:%S")
    end_str = next_date.strftime("%Y-%m-%d %H:%M:%S")

    # Replace placeholders
    query = (kpi["query_text"]
             .replace("{prev_month_start}", prev_str)
             .replace("{start_date}", start_str)
             .replace("{end_date}", end_str))

    logger.info("Modified PostgreSQL query: %s", query)
    results = db.execute_query(query)

    # Suppose the query returns (app_id, db_servicenow_id, report_date, etc.)
    for row in results:
        # Adjust indexing based on the actual columns returned
        app_id = row[0]
        metric_value = row[1]  # Example: row[1] might be db_servicenow_id or something else

        kpi_tracking_data.append((
            kpi["service_id"],
            kpi["configuration_id"],
            app_id,
            kpi["metric_name"],
            metric_value,
            current_date,
            next_date
        ))

def insert_kpi_tracking_data(db, kpi_tracking_data):
    """
    Insert KPI tracking data into the PostgreSQL tracking table.
    """
    if kpi_tracking_data:
        db.insert_kpi_tracking(kpi_tracking_data)

# -------------------------------------------------------------------------
# Main Execution Function
# -------------------------------------------------------------------------
def main_execution(start_date=None, end_date=None):
    """
    Main execution function for the KPI automation script.
    """
    db = None
    mssql = None
    try:
        # -------------------------
        # 1. Load Base Configuration
        # -------------------------
        config = CONFIG  # from config.py

        # -------------------------
        # 2. PostgreSQL Connection
        # -------------------------
        pg_config = {
            "pisi_db_server": config["PostgreSQL"]["PISI_DB_SERVER"],
            "pisi_db_port": config["PostgreSQL"]["PISI_DB_PORT"],
            "pisi_db_name": config["PostgreSQL"]["PISI_DB_NAME"],
            "pisi_db_user": config["PostgreSQL"]["PISI_DB_USER"],
            "pisi_db_pass": config["PostgreSQL"]["PISI_DB_PASS"]
        }
        db = PostgreSQL(pg_config)

        # -------------------------
        # 3. SQL Server Connection
        # -------------------------
        if not config["SQL Server"]["PISI_SERVICE_PASS"]:
            raise RuntimeError("Password for MSSQL user 'PISIAUTOMATION' is not set.")

        mssql_config = {
            "eft_datamart_host": config["SQL Server"]["EFT_DATAMART_HOST"],
            "eft_datamart_port": config["SQL Server"]["EFT_DATAMART_PORT"],
            "eft_datamart_instance": config["SQL Server"]["EFT_DATAMART_INSTANCE"],
            "pisi_service_user": config["SQL Server"]["PISI_SERVICE_USER"],
            "pisi_service_pass": config["SQL Server"]["PISI_SERVICE_PASS"],
            "eft_datamart_db_name": config["SQL Server"]["EFT_DATAMART_DB_NAME"]
        }
        mssql = MSSQLDatabase(mssql_config)

        # -------------------------
        # 4. JIRA Connection
        # -------------------------
        jira_proxy = JiraAPI(
            config["JIRA"]["JIRA_ENDPOINT"],
            config["JIRA"]["JIRA_TOKEN"]
        )

        # -------------------------
        # 5. Determine Date Range
        # -------------------------
        if start_date and end_date:
            current_date_obj = datetime.strptime(start_date, "%Y-%m-%d").replace(tzinfo=timezone.utc)
            end_date_obj = datetime.strptime(end_date, "%Y-%m-%d").replace(tzinfo=timezone.utc)
        else:
            today = datetime.now(timezone.utc)
            # For example, process only the previous day
            current_date_obj = today - timedelta(days=1)
            end_date_obj = today.replace(hour=0, minute=0, second=0, microsecond=0)

        # -------------------------
        # 6. Fetch KPI Configs
        # -------------------------
        kpi_measure_list = db.fetch_kpi_measure_list()

        # -------------------------
        # 7. Process Each KPI
        # -------------------------
        for kpi in kpi_measure_list:
            process_kpi(kpi, db, mssql, jira_proxy, current_date_obj, end_date_obj)

    except (psycopg2.Error, pymssql.Error, JIRAError, RequestException) as main_error:
        logger.error("Fatal error: %s", main_error)
    finally:
        # Clean up connections
        if db:
            db.close()
        if mssql:
            mssql.close()
        logger.info("Database connections closed.")

# -------------------------------------------------------------------------
# Entry Point
# -------------------------------------------------------------------------
if __name__ == "__main__":
    # 1. Parse CLI arguments for optional date range
    parser = argparse.ArgumentParser(description="KPI Automation Script")
    parser.add_argument("--start_date", type=str, help="Start date in YYYY-MM-DD format")
    parser.add_argument("--end_date", type=str, help="End date in YYYY-MM-DD format")
    args = parser.parse_args()

    # 2. Execute main logic
    main_execution(args.start_date, args.end_date)





def process_postgresql_kpi(kpi, db, current_date, next_date, kpi_tracking_data):
    # Grab the query template from kpi["query_text"] or wherever you store it
    query_template = kpi["query_text"]
    
    # Convert Python datetime objects to strings in your desired format
    # e.g., "YYYY/MM/DD HH:MM"
    start_str = current_date.strftime("%Y/%m/%d %H:%M")
    end_str = next_date.strftime("%Y/%m/%d %H:%M")

    # For the previous month date, do your own logic to compute it:
    # Example:
    prev_month = current_date.replace(day=1) - timedelta(days=1)
    prev_month_date_str = prev_month.strftime("%Y/%m/%d %H:%M")

    # Replace placeholders
    query = (
        query_template
        .replace("{start_date}", start_str)
        .replace("{end_date}", end_str)
        .replace("{prev_month_date}", prev_month_date_str)
    )

    logger.info("Executing PostgreSQL query: %s", query)
    results = db.execute_query(query)

    # Process results as needed
    for row in results:
        # Adjust indexes to match your columns (APP_ID, DB_SERVICENOW_ID, etc.)
        app_id = row[0]
        db_servicenow_id = row[1]
        report_date = row[2]
        
        # Append to tracking data




def process_sql_server_kpi(kpi, mssql, current_date, next_date, kpi_tracking_data):
    """
    Process KPI data from SQL Server for a given date range.
    """
    # Ensure current_date is a datetime object
    if not isinstance(current_date, datetime):
        raise ValueError("current_date must be a datetime object")

    # Calculate the previous month's start date
    first_day_current_month = current_date.replace(day=1)
    prev_month_start = first_day_current_month - timedelta(days=1)
    prev_month_start = prev_month_start.replace(day=1, hour=0, minute=0, second=0, microsecond=0, tzinfo=timezone.utc)

    print(f"Calculated prev_month_start: {prev_month_start}")  # Debugging output

    # Ensure prev_month_start is a string before replacing
    if not isinstance(prev_month_start, datetime):
        raise TypeError(f"prev_month_start is not a datetime object: {type(prev_month_start)}")

    # Debug raw query
    print(f"Raw Query: {kpi['query_text']}")

    # Replace placeholders in query
    query = kpi["query_text"]
    query = query.replace("{start_date}", current_date.strftime("%Y/%m/%d %H:%M"))
    print(f"After start_date replacement: {query}")

    query = query.replace("{end_date}", next_date.strftime("%Y/%m/%d %H:%M"))
    print(f"After end_date replacement: {query}")

    query = query.replace("{prev_month_start}", prev_month_start.strftime("%Y/%m/%d %H:%M"))
    print(f"After prev_month_start replacement: {query}")

    # Print the query for debugging
    logger.info(f"Executing query: {query}")
    print(f"Executing query: {query}")  # Debugging output

    # Execute the query
    results = mssql.execute_query(query)

    return results



SELECT
    '{start_date}'::timestamp AS start_date,
    '{end_date}'::timestamp AS end_date,
    '{prev_month_start}'::timestamp AS prev_month_start,
    "APP_ID",
    "DB_SERVICENOW_ID",
    "REPORT_DATE"
FROM (
    SELECT DISTINCT
        "DB_SERVICENOW_ID",
        "REPORT_DATE",
        "ENCRYPTED",
        "APP_ID",
        "JIRA_TICKET_NUMBER"
    FROM (
        SELECT
            FIRST_VALUE("REPORT_DATE") OVER (
                PARTITION BY "DB_SERVICENOW_ID", "ENCRYPTED"
                ORDER BY "REPORT_DATE" DESC
            ) AS "REPORT_DATE",
            "JIRA_TICKET_NUMBER",
            "APP_ID"
        FROM "PSI_AUTOMATION"."DATABASE_ENCRYPTION_HISTORY"
        WHERE "REPORT_DATE" BETWEEN '{prev_month_start}' AND '{end_date}'
          AND "JIRA_TICKET_NUMBER" IS NOT NULL
    ) x
) y
WHERE "ENCRYPTED" = '1'
  AND "REPORT_DATE" BETWEEN '{prev_month_start}' AND '{end_date}';

